{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "minor_project_ANN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNGvaZAxM34XXUv6CYqzHok",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/archana3001/DeepLearning_Beginner/blob/master/minor_project_ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Implement ANN**"
      ],
      "metadata": {
        "id": "Y7AwD7YqGl1J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**HyperParameters Optimisation**\n",
        "\n",
        "Here we will be choosing optimal values for these hyperparameters :\n",
        "\n",
        " these hyperparameters are :\n",
        "1. learning rate\n",
        "2. no of hidden layers ( no of layers we want between input layer and output layer )\n",
        "2. no of neurons ( no of nodes we want in each layers)\n",
        "3. weight ( using weight initialization )\n",
        "4. batch ( finding batch size for mini batch sdg )\n",
        "5. momentum ( finding momentum )\n"
      ],
      "metadata": {
        "id": "-clmHGZrGug5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3eAOmE8_K5Ne",
        "outputId": "9c439f10-dc5b-4edc-896e-ae62f551befa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U keras-tuner"
      ],
      "metadata": {
        "id": "2DHP1sADL732"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from kerastuner.tuners import RandomSearch "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTpK5ZsyGtQZ",
        "outputId": "549a73c5-861c-4095-b0e1-78654b3e4079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/drive/MyDrive/AILAB/Constraint_English_Train - Constraint_English_Train.csv')"
      ],
      "metadata": {
        "id": "C2jwPa32Kg3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "8k5h0E6dKuTY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "bd6c322c-9b8a-4d09-a1c4-ee694d11b115"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a4fc6a6a-e1e6-4ccd-b818-9cc0a9df55e4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>The CDC currently reports 99031 deaths. In gen...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>States reported 1121 deaths a small rise from ...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Politically Correct Woman (Almost) Uses Pandem...</td>\n",
              "      <td>fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>#IndiaFightsCorona: We have 1524 #COVID testin...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Populous states can generate large case counts...</td>\n",
              "      <td>real</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4fc6a6a-e1e6-4ccd-b818-9cc0a9df55e4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a4fc6a6a-e1e6-4ccd-b818-9cc0a9df55e4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a4fc6a6a-e1e6-4ccd-b818-9cc0a9df55e4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   id                                              tweet label\n",
              "0   1  The CDC currently reports 99031 deaths. In gen...  real\n",
              "1   2  States reported 1121 deaths a small rise from ...  real\n",
              "2   3  Politically Correct Woman (Almost) Uses Pandem...  fake\n",
              "3   4  #IndiaFightsCorona: We have 1524 #COVID testin...  real\n",
              "4   5  Populous states can generate large case counts...  real"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Step 1 : Here we performing vectorisation on our dataset**"
      ],
      "metadata": {
        "id": "bkIWIFKDMWhs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Method 1 : WordEmbedding "
      ],
      "metadata": {
        "id": "60-qr9bRNZpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from sklearn import preprocessing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vZwiNPxMUDu",
        "outputId": "78757be9-4c53-4f3e-ccfd-e7cf8285308c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#text preprocessing and cleaning\n",
        "corpus=[]\n",
        "for i in range(0, len(df)):\n",
        "  tweet=re.sub('[^a-zA-Z]', ' ',df['tweet'][i])\n",
        "  tweet=tweet.lower()\n",
        "  tweet=tweet.split()\n",
        "  tweet=[word for word in tweet if not word in stopwords.words('english')]\n",
        "  tweet=' '.join(tweet)\n",
        "  corpus.append(tweet)\n",
        "\n",
        "#one hot representation\n",
        "voc_size=10000\n",
        "one_hot_rep=[one_hot(words, voc_size) for words in corpus]\n",
        "\n",
        "#embedding\n",
        "embedded_doc=pad_sequences(one_hot_rep, padding='pre', maxlen=50) #we are making each sentences of word 50 if len(sentence)<50 we add 0 as prefix words\n",
        "dim=100  #here dimension is no of features we want for embedding\n",
        "model=Sequential()\n",
        "model.add(Embedding(voc_size, dim, input_length=50)) #vocab_size, dimension and sentence length are parameters\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) # compile the model\n",
        "#print(model.summary())  # summarize the model\n",
        "\n",
        "# let's see how our embedded doc is fitted to embedding model \n",
        "X=embedded_doc\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "df['label']= label_encoder.fit_transform(df['label'])\n",
        "y=df['label']\n",
        "#print(y.shape)\n",
        "#print(X.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "M7JquB3JNwlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X, y, epochs=50, verbose=0) # fit the model\n",
        "loss, accuracy = model.evaluate(X, y, verbose=0) # evaluate the model\n",
        "print('Accuracy: %f' % (accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGY9LUn1TvZc",
        "outputId": "d70ca8d1-ae0b-4b22-aaf8-4b36ec8ad2bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 100.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**train test split**"
      ],
      "metadata": {
        "id": "oL9U3CIuVUAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Train Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test=train_test_split(X,y, test_size=0.25, random_state=0)"
      ],
      "metadata": {
        "id": "fGd6WHkoVXdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Deciding no of hidden layers and neurons in each layer**"
      ],
      "metadata": {
        "id": "e31V_xnNVB8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hyperparams):\n",
        "  modelhp=keras.Sequential()\n",
        "  #we are selecting no of hidden layers layers between 2 to 30\n",
        "  for i in range(hyperparams.Int('num_layers', 2, 30)):\n",
        "    #inside each layer we are defining no of neurons that is here 4 to 512\n",
        "    #we are selecting relu as activation function for hidden layers\n",
        "    modelhp.add(layers.Dense(units=hyperparams.Int('units_'+str(i), min_value=4, max_value=512, step=32),activation='relu'))\n",
        "\n",
        "  modelhp.add(layers.Dense(1, activation='linear')) # adding one output layer and activation function as sigmoid as it is a classification problem\n",
        "  modelhp.compile(optimizer=keras.optimizers.Adam(hyperparams.Choice('learning rate',[1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7])),loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  return modelhp"
      ],
      "metadata": {
        "id": "ckdLc-XbU9xY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from kerastuner.tuners import RandomSearch\n",
        "#We use objective to specify the objective to select the best models, and we use max_trials to specify the number of different models to try.\n",
        "tuner=RandomSearch(build_model, objective='val_accuracy', max_trials=20)\n",
        "tuner.search(X_train, y_train, epochs=5, validation_data=(X_test, y_test))\n",
        "best_model = tuner.get_best_models()[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePLpC3h4YKqw",
        "outputId": "d3fc26ce-af02-4de2-cd09-cd676e6fb86a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Reloading Oracle from existing project ./untitled_project/oracle.json\n",
            "INFO:tensorflow:Reloading Tuner from ./untitled_project/tuner0.json\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.results_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39jgMzCeZEin",
        "outputId": "77dbd628-8547-48e9-b16f-5b4b80b4de8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in ./untitled_project\n",
            "Showing 10 best trials\n",
            "Objective(name='val_accuracy', direction='max')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 28\n",
            "units_0: 4\n",
            "units_1: 228\n",
            "learning rate: 0.0001\n",
            "units_2: 484\n",
            "units_3: 420\n",
            "units_4: 164\n",
            "units_5: 164\n",
            "units_6: 228\n",
            "units_7: 132\n",
            "units_8: 4\n",
            "units_9: 36\n",
            "units_10: 164\n",
            "units_11: 452\n",
            "units_12: 356\n",
            "units_13: 132\n",
            "units_14: 36\n",
            "units_15: 420\n",
            "units_16: 228\n",
            "units_17: 484\n",
            "units_18: 484\n",
            "units_19: 260\n",
            "units_20: 36\n",
            "units_21: 132\n",
            "units_22: 484\n",
            "units_23: 388\n",
            "units_24: 228\n",
            "units_25: 484\n",
            "units_26: 452\n",
            "units_27: 4\n",
            "Score: 0.6922118663787842\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 23\n",
            "units_0: 484\n",
            "units_1: 324\n",
            "learning rate: 1e-06\n",
            "units_2: 452\n",
            "units_3: 4\n",
            "units_4: 260\n",
            "units_5: 260\n",
            "units_6: 228\n",
            "units_7: 68\n",
            "units_8: 228\n",
            "units_9: 452\n",
            "units_10: 388\n",
            "units_11: 164\n",
            "units_12: 196\n",
            "units_13: 228\n",
            "units_14: 36\n",
            "units_15: 196\n",
            "units_16: 196\n",
            "units_17: 452\n",
            "units_18: 164\n",
            "units_19: 356\n",
            "units_20: 68\n",
            "units_21: 228\n",
            "units_22: 356\n",
            "units_23: 324\n",
            "units_24: 68\n",
            "units_25: 36\n",
            "units_26: 292\n",
            "Score: 0.688265860080719\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 25\n",
            "units_0: 388\n",
            "units_1: 68\n",
            "learning rate: 0.001\n",
            "units_2: 132\n",
            "units_3: 484\n",
            "units_4: 228\n",
            "units_5: 260\n",
            "units_6: 36\n",
            "units_7: 356\n",
            "units_8: 484\n",
            "units_9: 100\n",
            "units_10: 132\n",
            "units_11: 228\n",
            "units_12: 484\n",
            "units_13: 228\n",
            "units_14: 356\n",
            "units_15: 4\n",
            "units_16: 68\n",
            "units_17: 452\n",
            "units_18: 36\n",
            "units_19: 484\n",
            "units_20: 68\n",
            "units_21: 260\n",
            "units_22: 36\n",
            "units_23: 228\n",
            "units_24: 228\n",
            "units_25: 324\n",
            "units_26: 420\n",
            "Score: 0.5742471218109131\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 13\n",
            "units_0: 260\n",
            "units_1: 68\n",
            "learning rate: 0.0001\n",
            "units_2: 388\n",
            "units_3: 452\n",
            "units_4: 100\n",
            "units_5: 420\n",
            "units_6: 100\n",
            "units_7: 452\n",
            "units_8: 100\n",
            "units_9: 484\n",
            "units_10: 100\n",
            "units_11: 36\n",
            "units_12: 324\n",
            "units_13: 484\n",
            "units_14: 100\n",
            "units_15: 292\n",
            "units_16: 292\n",
            "units_17: 164\n",
            "units_18: 68\n",
            "units_19: 484\n",
            "units_20: 260\n",
            "units_21: 484\n",
            "units_22: 164\n",
            "units_23: 228\n",
            "units_24: 292\n",
            "units_25: 388\n",
            "units_26: 228\n",
            "Score: 0.5503634214401245\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 20\n",
            "units_0: 452\n",
            "units_1: 228\n",
            "learning rate: 0.001\n",
            "units_2: 292\n",
            "units_3: 196\n",
            "units_4: 36\n",
            "units_5: 100\n",
            "units_6: 36\n",
            "units_7: 164\n",
            "units_8: 292\n",
            "units_9: 452\n",
            "units_10: 356\n",
            "units_11: 164\n",
            "units_12: 36\n",
            "units_13: 132\n",
            "units_14: 388\n",
            "units_15: 356\n",
            "units_16: 452\n",
            "units_17: 164\n",
            "units_18: 36\n",
            "units_19: 388\n",
            "units_20: 484\n",
            "units_21: 388\n",
            "units_22: 484\n",
            "units_23: 260\n",
            "units_24: 228\n",
            "units_25: 452\n",
            "units_26: 324\n",
            "Score: 0.5248183012008667\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 5\n",
            "units_0: 100\n",
            "units_1: 452\n",
            "learning rate: 1e-05\n",
            "units_2: 68\n",
            "units_3: 36\n",
            "units_4: 164\n",
            "units_5: 164\n",
            "units_6: 228\n",
            "units_7: 484\n",
            "units_8: 484\n",
            "units_9: 228\n",
            "units_10: 452\n",
            "units_11: 324\n",
            "units_12: 36\n",
            "units_13: 36\n",
            "units_14: 420\n",
            "units_15: 132\n",
            "units_16: 196\n",
            "units_17: 68\n",
            "units_18: 484\n",
            "units_19: 68\n",
            "units_20: 196\n",
            "units_21: 484\n",
            "units_22: 132\n",
            "units_23: 356\n",
            "units_24: 292\n",
            "units_25: 324\n",
            "units_26: 484\n",
            "Score: 0.5248183012008667\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 10\n",
            "units_0: 164\n",
            "units_1: 164\n",
            "learning rate: 0.01\n",
            "units_2: 132\n",
            "units_3: 260\n",
            "units_4: 260\n",
            "units_5: 36\n",
            "units_6: 100\n",
            "units_7: 420\n",
            "units_8: 100\n",
            "units_9: 484\n",
            "units_10: 388\n",
            "units_11: 324\n",
            "units_12: 452\n",
            "units_13: 164\n",
            "units_14: 484\n",
            "units_15: 100\n",
            "units_16: 420\n",
            "units_17: 388\n",
            "units_18: 132\n",
            "units_19: 100\n",
            "units_20: 36\n",
            "units_21: 100\n",
            "units_22: 228\n",
            "units_23: 228\n",
            "units_24: 68\n",
            "units_25: 388\n",
            "units_26: 260\n",
            "units_27: 388\n",
            "Score: 0.5190030932426453\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 18\n",
            "units_0: 100\n",
            "units_1: 164\n",
            "learning rate: 0.001\n",
            "units_2: 324\n",
            "units_3: 196\n",
            "units_4: 4\n",
            "units_5: 292\n",
            "units_6: 260\n",
            "units_7: 388\n",
            "units_8: 164\n",
            "units_9: 68\n",
            "units_10: 36\n",
            "units_11: 132\n",
            "units_12: 356\n",
            "units_13: 452\n",
            "units_14: 196\n",
            "units_15: 36\n",
            "units_16: 100\n",
            "units_17: 132\n",
            "units_18: 164\n",
            "units_19: 260\n",
            "units_20: 324\n",
            "units_21: 4\n",
            "units_22: 100\n",
            "units_23: 196\n",
            "units_24: 228\n",
            "units_25: 260\n",
            "units_26: 356\n",
            "Score: 0.48099687695503235\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 21\n",
            "units_0: 36\n",
            "units_1: 292\n",
            "learning rate: 0.01\n",
            "units_2: 228\n",
            "units_3: 164\n",
            "units_4: 420\n",
            "units_5: 452\n",
            "units_6: 324\n",
            "units_7: 420\n",
            "units_8: 196\n",
            "units_9: 68\n",
            "units_10: 164\n",
            "units_11: 164\n",
            "units_12: 132\n",
            "units_13: 292\n",
            "units_14: 356\n",
            "units_15: 452\n",
            "units_16: 420\n",
            "units_17: 484\n",
            "units_18: 484\n",
            "units_19: 100\n",
            "units_20: 196\n",
            "units_21: 324\n",
            "units_22: 164\n",
            "units_23: 228\n",
            "units_24: 68\n",
            "units_25: 228\n",
            "units_26: 164\n",
            "Score: 0.48099687695503235\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 14\n",
            "units_0: 228\n",
            "units_1: 4\n",
            "learning rate: 1e-05\n",
            "units_2: 356\n",
            "units_3: 68\n",
            "units_4: 388\n",
            "units_5: 132\n",
            "units_6: 100\n",
            "units_7: 68\n",
            "units_8: 292\n",
            "units_9: 388\n",
            "units_10: 164\n",
            "units_11: 356\n",
            "units_12: 356\n",
            "units_13: 356\n",
            "units_14: 420\n",
            "units_15: 228\n",
            "units_16: 420\n",
            "units_17: 420\n",
            "units_18: 100\n",
            "units_19: 484\n",
            "units_20: 356\n",
            "units_21: 164\n",
            "units_22: 4\n",
            "units_23: 260\n",
            "units_24: 4\n",
            "units_25: 388\n",
            "units_26: 164\n",
            "units_27: 484\n",
            "Score: 0.48099687695503235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Applying ANN to embedded data after selecting suitable hyperparameters**"
      ],
      "metadata": {
        "id": "kEbT3EoFdPs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Scaling test and train data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc=StandardScaler()\n",
        "X_train=sc.fit_transform(X_train)\n",
        "X_test=sc.transform(X_test)"
      ],
      "metadata": {
        "id": "7IHDQVzbb8CM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RY7vZJYsfRKf",
        "outputId": "1b5bf009-1541-4eba-c4f7-14c92297af7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4815, 50)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Single hidden layer**"
      ],
      "metadata": {
        "id": "dK3s1QIKg5T8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "classifier = Sequential() #create sequential model named as classifier\n",
        "#units defines the size of the output from the dense layer\n",
        "classifier.add(Dense(units=1, kernel_initializer='he_normal', activation='relu', input_dim=50)) #input layer\n",
        "classifier.add(Dense(units=4, kernel_initializer='he_normal', activation='relu')) # 1 hidden layer with \n",
        "classifier.add(Dense(units=1, kernel_initializer='he_normal', activation='sigmoid')) # 1 output layer\n",
        "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) #compile simple ANN\n",
        "model_history = classifier.fit(X_train, y_train, validation_split=0.33, batch_size=10, epochs=21)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GlG34N0g3mg",
        "outputId": "865fafed-6c6c-4a1c-a894-621eb6ec6d14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/21\n",
            "323/323 [==============================] - 1s 3ms/step - loss: 0.6839 - accuracy: 0.6438 - val_loss: 0.6611 - val_accuracy: 0.6394\n",
            "Epoch 2/21\n",
            "323/323 [==============================] - 1s 3ms/step - loss: 0.6422 - accuracy: 0.6723 - val_loss: 0.6354 - val_accuracy: 0.6715\n",
            "Epoch 3/21\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 0.6173 - accuracy: 0.6990 - val_loss: 0.6178 - val_accuracy: 0.6847\n",
            "Epoch 4/21\n",
            "323/323 [==============================] - 1s 3ms/step - loss: 0.5997 - accuracy: 0.7126 - val_loss: 0.6072 - val_accuracy: 0.6941\n",
            "Epoch 5/21\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 0.5880 - accuracy: 0.7207 - val_loss: 0.5997 - val_accuracy: 0.7048\n",
            "Epoch 6/21\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 0.5806 - accuracy: 0.7263 - val_loss: 0.5960 - val_accuracy: 0.7067\n",
            "Epoch 7/21\n",
            "323/323 [==============================] - 1s 3ms/step - loss: 0.5753 - accuracy: 0.7241 - val_loss: 0.5920 - val_accuracy: 0.7067\n",
            "Epoch 8/21\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 0.5701 - accuracy: 0.7254 - val_loss: 0.5899 - val_accuracy: 0.7162\n",
            "Epoch 9/21\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 0.5667 - accuracy: 0.7254 - val_loss: 0.5865 - val_accuracy: 0.7137\n",
            "Epoch 10/21\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 0.5632 - accuracy: 0.7297 - val_loss: 0.5843 - val_accuracy: 0.7187\n",
            "Epoch 11/21\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 0.5599 - accuracy: 0.7281 - val_loss: 0.5825 - val_accuracy: 0.7237\n",
            "Epoch 12/21\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 0.5567 - accuracy: 0.7309 - val_loss: 0.5802 - val_accuracy: 0.7206\n",
            "Epoch 13/21\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 0.5542 - accuracy: 0.7340 - val_loss: 0.5805 - val_accuracy: 0.7294\n",
            "Epoch 14/21\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 0.5527 - accuracy: 0.7356 - val_loss: 0.5758 - val_accuracy: 0.7294\n",
            "Epoch 15/21\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 0.5505 - accuracy: 0.7356 - val_loss: 0.5740 - val_accuracy: 0.7294\n",
            "Epoch 16/21\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 0.5480 - accuracy: 0.7368 - val_loss: 0.5705 - val_accuracy: 0.7262\n",
            "Epoch 17/21\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 0.5444 - accuracy: 0.7374 - val_loss: 0.5688 - val_accuracy: 0.7325\n",
            "Epoch 18/21\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 0.5423 - accuracy: 0.7374 - val_loss: 0.5661 - val_accuracy: 0.7281\n",
            "Epoch 19/21\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 0.5387 - accuracy: 0.7387 - val_loss: 0.5620 - val_accuracy: 0.7237\n",
            "Epoch 20/21\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 0.5363 - accuracy: 0.7405 - val_loss: 0.5605 - val_accuracy: 0.7306\n",
            "Epoch 21/21\n",
            "323/323 [==============================] - 1s 2ms/step - loss: 0.5345 - accuracy: 0.7381 - val_loss: 0.5562 - val_accuracy: 0.7325\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#making prediction and evaluating simple ANN\n",
        "y_pred_single_layer=classifier.predict(X_test)\n",
        "y_pred_single_layer=(y_pred_single_layer>0.5)"
      ],
      "metadata": {
        "id": "wK_vB_NriZx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#y_new=y_pred_single_layer.flatten()"
      ],
      "metadata": {
        "id": "by8oAesty_ow"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating confusion matrix\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm=confusion_matrix(y_test, y_pred_single_layer)\n",
        "\n",
        "#calculating accuracy\n",
        "score=accuracy_score(y_pred_single_layer, y_test)"
      ],
      "metadata": {
        "id": "dHAeHswQkKDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cm)\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hu5TlMHkS49",
        "outputId": "6640d83f-cc27-4a98-aa02-bbdbea1797ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[505 267]\n",
            " [196 637]]\n",
            "0.7115264797507788\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**building and checking summary of best_model we get after tuning**"
      ],
      "metadata": {
        "id": "Z6cvGs9b4iQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape\n",
        "best_model.build(X_train.shape)\n",
        "best_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vt6X3Ytu2BQw",
        "outputId": "cf98bf12-d44c-4362-a00f-5d5f65bcae09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (4815, 4)                 204       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (4815, 228)               1140      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (4815, 484)               110836    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (4815, 420)               203700    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (4815, 164)               69044     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (4815, 164)               27060     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (4815, 228)               37620     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (4815, 132)               30228     \n",
            "                                                                 \n",
            " dense_8 (Dense)             (4815, 4)                 532       \n",
            "                                                                 \n",
            " dense_9 (Dense)             (4815, 36)                180       \n",
            "                                                                 \n",
            " dense_10 (Dense)            (4815, 164)               6068      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (4815, 452)               74580     \n",
            "                                                                 \n",
            " dense_12 (Dense)            (4815, 356)               161268    \n",
            "                                                                 \n",
            " dense_13 (Dense)            (4815, 132)               47124     \n",
            "                                                                 \n",
            " dense_14 (Dense)            (4815, 36)                4788      \n",
            "                                                                 \n",
            " dense_15 (Dense)            (4815, 420)               15540     \n",
            "                                                                 \n",
            " dense_16 (Dense)            (4815, 228)               95988     \n",
            "                                                                 \n",
            " dense_17 (Dense)            (4815, 484)               110836    \n",
            "                                                                 \n",
            " dense_18 (Dense)            (4815, 484)               234740    \n",
            "                                                                 \n",
            " dense_19 (Dense)            (4815, 260)               126100    \n",
            "                                                                 \n",
            " dense_20 (Dense)            (4815, 36)                9396      \n",
            "                                                                 \n",
            " dense_21 (Dense)            (4815, 132)               4884      \n",
            "                                                                 \n",
            " dense_22 (Dense)            (4815, 484)               64372     \n",
            "                                                                 \n",
            " dense_23 (Dense)            (4815, 388)               188180    \n",
            "                                                                 \n",
            " dense_24 (Dense)            (4815, 228)               88692     \n",
            "                                                                 \n",
            " dense_25 (Dense)            (4815, 484)               110836    \n",
            "                                                                 \n",
            " dense_26 (Dense)            (4815, 452)               219220    \n",
            "                                                                 \n",
            " dense_27 (Dense)            (4815, 4)                 1812      \n",
            "                                                                 \n",
            " dense_28 (Dense)            (4815, 1)                 5         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,044,973\n",
            "Trainable params: 2,044,973\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**fitting our training data to best_model and predicting for test data and then calculating accuracy**"
      ],
      "metadata": {
        "id": "O2YXgmv445pg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.fit(X_train, y_train,epochs=34,batch_size=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYwlo03F2yqS",
        "outputId": "10dce30a-a5e5-488b-d015-fa0d5dac9728"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/34\n",
            "482/482 [==============================] - 12s 22ms/step - loss: 0.6431 - accuracy: 0.6307\n",
            "Epoch 2/34\n",
            "482/482 [==============================] - 10s 21ms/step - loss: 0.6109 - accuracy: 0.6891\n",
            "Epoch 3/34\n",
            "482/482 [==============================] - 10s 21ms/step - loss: 0.6000 - accuracy: 0.7067\n",
            "Epoch 4/34\n",
            "482/482 [==============================] - 10s 22ms/step - loss: 0.6180 - accuracy: 0.6827\n",
            "Epoch 5/34\n",
            "482/482 [==============================] - 10s 22ms/step - loss: 0.5788 - accuracy: 0.7178\n",
            "Epoch 6/34\n",
            "482/482 [==============================] - 10s 22ms/step - loss: 0.5735 - accuracy: 0.7227\n",
            "Epoch 7/34\n",
            "482/482 [==============================] - 10s 22ms/step - loss: 0.5659 - accuracy: 0.7221\n",
            "Epoch 8/34\n",
            "482/482 [==============================] - 10s 21ms/step - loss: 0.5648 - accuracy: 0.7205\n",
            "Epoch 9/34\n",
            "482/482 [==============================] - 10s 21ms/step - loss: 0.5560 - accuracy: 0.7302\n",
            "Epoch 10/34\n",
            "482/482 [==============================] - 10s 22ms/step - loss: 0.5596 - accuracy: 0.7288\n",
            "Epoch 11/34\n",
            "482/482 [==============================] - 10s 22ms/step - loss: 0.5507 - accuracy: 0.7321\n",
            "Epoch 12/34\n",
            "482/482 [==============================] - 10s 22ms/step - loss: 0.5484 - accuracy: 0.7335\n",
            "Epoch 13/34\n",
            "482/482 [==============================] - 10s 21ms/step - loss: 0.5475 - accuracy: 0.7323\n",
            "Epoch 14/34\n",
            "482/482 [==============================] - 10s 21ms/step - loss: 0.5473 - accuracy: 0.7331\n",
            "Epoch 15/34\n",
            "482/482 [==============================] - 10s 22ms/step - loss: 0.5426 - accuracy: 0.7358\n",
            "Epoch 16/34\n",
            "482/482 [==============================] - 10s 22ms/step - loss: 0.5451 - accuracy: 0.7358\n",
            "Epoch 17/34\n",
            "482/482 [==============================] - 10s 22ms/step - loss: 0.5457 - accuracy: 0.7383\n",
            "Epoch 18/34\n",
            "482/482 [==============================] - 10s 21ms/step - loss: 0.5367 - accuracy: 0.7375\n",
            "Epoch 19/34\n",
            "482/482 [==============================] - 11s 22ms/step - loss: 0.5366 - accuracy: 0.7406\n",
            "Epoch 20/34\n",
            "482/482 [==============================] - 10s 21ms/step - loss: 0.5381 - accuracy: 0.7394\n",
            "Epoch 21/34\n",
            "482/482 [==============================] - 10s 22ms/step - loss: 0.5370 - accuracy: 0.7377\n",
            "Epoch 22/34\n",
            "482/482 [==============================] - 11s 22ms/step - loss: 0.5357 - accuracy: 0.7391\n",
            "Epoch 23/34\n",
            "482/482 [==============================] - 11s 22ms/step - loss: 0.5337 - accuracy: 0.7402\n",
            "Epoch 24/34\n",
            "482/482 [==============================] - 11s 23ms/step - loss: 0.5345 - accuracy: 0.7381\n",
            "Epoch 25/34\n",
            "482/482 [==============================] - 11s 22ms/step - loss: 0.5338 - accuracy: 0.7416\n",
            "Epoch 26/34\n",
            "482/482 [==============================] - 11s 22ms/step - loss: 0.5364 - accuracy: 0.7400\n",
            "Epoch 27/34\n",
            "482/482 [==============================] - 10s 22ms/step - loss: 0.5313 - accuracy: 0.7375\n",
            "Epoch 28/34\n",
            "482/482 [==============================] - 11s 22ms/step - loss: 0.5319 - accuracy: 0.7383\n",
            "Epoch 29/34\n",
            "482/482 [==============================] - 11s 22ms/step - loss: 0.5323 - accuracy: 0.7389\n",
            "Epoch 30/34\n",
            "482/482 [==============================] - 11s 22ms/step - loss: 0.5442 - accuracy: 0.7450\n",
            "Epoch 31/34\n",
            "482/482 [==============================] - 10s 22ms/step - loss: 0.5432 - accuracy: 0.7443\n",
            "Epoch 32/34\n",
            "482/482 [==============================] - 10s 21ms/step - loss: 0.5556 - accuracy: 0.7277\n",
            "Epoch 33/34\n",
            "482/482 [==============================] - 10s 22ms/step - loss: 0.5348 - accuracy: 0.7450\n",
            "Epoch 34/34\n",
            "482/482 [==============================] - 11s 22ms/step - loss: 0.5370 - accuracy: 0.7423\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe9bba94f50>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_best_pred=best_model.predict(X_test)\n",
        "y_best_pred=y_best_pred.flatten()\n",
        "y_best_pred=(y_best_pred>0.5)"
      ],
      "metadata": {
        "id": "LmQciL2H-Xtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#confusion matrix and accuracy score for best_model we get after hyperparameter tuning in keras\n",
        "cm_best=confusion_matrix(y_test, y_best_pred)\n",
        "\n",
        "#calculating accuracy\n",
        "score_best=accuracy_score(y_best_pred, y_test)\n",
        "\n",
        "print(\"confusion matrix : \\n\", cm_best)\n",
        "print(\"score : \",score_best)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7tS4BMb5cHk",
        "outputId": "f1054720-aaff-4d36-9de6-03a110b64b5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confusion matrix : \n",
            " [[473 299]\n",
            " [146 687]]\n",
            "score :  0.7227414330218068\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rf-O2CN8-kS3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}